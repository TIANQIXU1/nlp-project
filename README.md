# nlp-project
Code and data for the paper:
Abstract here:

## Data (training and test)
### Training data

### Test data

## Fine-tuning opus-mt-en-zh
In the first phase, 
## Fine-tuning Qwen2.5 1.5B
Prompts are created using the 'create_prompt'function
## Inference

### Tokenizers
* **1.5B Qwen2.5 model**

### Translation

## Evaluation
Evaluation was done based on BLEU and human evaluation.
